# Meridian Environment Configuration
# Copy this file to .env and fill in your values


# === API Keys ===

# DeepSeek API Key (recommended - best value)
DEEPSEEK_API_KEY=

# OpenAI API Key (for GPT-3.5, GPT-4)
OPENAI_API_KEY=

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=

# Mistral API Key
MISTRAL_API_KEY=

# Groq API Key (ultra-fast inference)
GROQ_API_KEY=

# Together API Key (open models)
TOGETHER_API_KEY=


# Default model to use
DEFAULT_MODEL=local_gpt2

# Local model cache directory
HF_HOME=~/.cache/huggingface

# Device for local models (cuda, cpu, mps)
DEVICE=cpu


# SQLite database path
DATABASE_PATH=./data/circuiteval.db

# Results storage directory
RESULTS_DIR=./data/results


# Maximum concurrent requests (for API models)
MAX_CONCURRENT_REQUESTS=5

# Request timeout in seconds
REQUEST_TIMEOUT=60

# Retry attempts for failed requests
MAX_RETRIES=3


# Streamlit server port
STREAMLIT_PORT=8501

# Enable debug mode
DEBUG=false


# Reports output directory
REPORTS_DIR=./reports/output

# Default report format (html, markdown)
DEFAULT_REPORT_FORMAT=html


# === Webhooks ===

# Webhook URL (Slack, Discord, Teams, or custom)
WEBHOOK_URL=

# Webhook type: slack, discord, teams, generic
WEBHOOK_TYPE=slack

# Enable/disable webhook notifications
WEBHOOK_ENABLED=true


# === CI/CD Thresholds ===

# Fail CI if accuracy drops below this threshold (0-1)
CI_ACCURACY_THRESHOLD=0.5

# Fail CI if latency exceeds this (ms)
CI_LATENCY_MAX_MS=5000

# Fail CI if hallucination rate exceeds this (0-1)
CI_HALLUCINATION_MAX_RATE=0.3

